#!/usr/bin/perl
use strict;
use warnings;

my $DEFAULT_SONG_VOLUME = 0.4;
my $DEFAULT_CAMERA_VOLUME = 12.0;

my @INITIAL_OPTS;
my @EXTRA_OPTS = qw(-bitexact);

sub isFile($);
sub ffmpeg($@);

my $usage = "Usage:
  $0 [OPTS]
    use ffmpeg to combine CAMERA_VIDEO and SCREEN_VIDEO and optional SONG_AUDIO files
    produces tmp files named 'tmp-*' in the current directory,
      and writes final video to OUTPUT_FILE

  OPTS
    --camera=CAMERA_VIDEO
      the file of the main camera video

    --screen=SCREEN_VIDEO
      the file of the screencast video

    --song=SONG_AUDIO
      an audio file to overlay the camera video
      (optional)

    --output=OUTPUT_FILE
      the file to write the final video to

    --ffmpeg-initial-opts=FFMPEG_INITIAL_OPTS
      space-separated list of arguments to put immediately after `ffmpeg` in each command

    --use-screen-audio
      overlay the audio from SCREEN_VIDEO on the camera video (using SCREEN_POINT to align)

    --longest-audio
      use longest instead of shortest, and specify the audio overlay before the camera audio

    -a | --audio-only | --stop-after-audio
      halt after processing the audio instead of processing the video and combining

    --camera-volume=SONG_VOLUME
      scale audio volume of CAMERA_VIDEO file (default is $DEFAULT_CAMERA_VOLUME)

    --song-volume=SONG_VOLUME
      scale audio volume of SONG_AUDIO file (default is $DEFAULT_SONG_VOLUME)

    --camera-audio-offset=OFFSET
      the audio offset, in seconds, in CAMERA_VIDEO
      (use positive values when the audio is happening before the video, to correct the delay)

    --camera-audio-point=CAMERA_AUDIO_POINT
    --screen-point=SCREEN_POINT
    --song-point=SONG_POINT
      the times, in (fractional) seconds, when all of the following are aligned:
        the audio of CAMERA_VIDEO at CAMERA_AUDIO_POINT (before correcting audio offset)
        the video of SCREEN_VIDEO at SCREEN_POINT
        the audio of SONG_AUDIO at SONG_POINT (if SONG_AUDIO is given)
        the audio of SCREEN_VIDEO at SCREEN_POINT (if --use-screen-audio is given)
      if not given, each value defaults to 0
";

sub main(@){
  my ($cameraFile, $screenFile, $songFile, $outputFile);
  my $cameraVolume = $DEFAULT_CAMERA_VOLUME;
  my $songVolume = $DEFAULT_SONG_VOLUME;
  my $cameraAVSyncOffset = 0;
  my $cameraAudioPoint = 0;
  my $screenPoint = 0;
  my $songPoint = 0;
  my $useScreenAudio = 0;
  my $longestAudio = 0;
  my $audioOnly = 0;
  while(@_ > 0){
    my $arg = shift;
    if($arg =~ /^(-h|--help)$/){
      print $usage;
      exit 0;
    }elsif($arg =~ /^--camera=(.+)$/){
      $cameraFile = $1;
    }elsif($arg =~ /^--screen=(.+)$/){
      $screenFile = $1;
    }elsif($arg =~ /^--song=(.+)$/){
      $songFile = $1;
    }elsif($arg =~ /^--output=(.+)$/){
      $outputFile = $1;
    }elsif($arg =~ /^--ffmpeg-initial-opts=(.+)$/){
      my $argList = $1;
      @INITIAL_OPTS = split /\s+/, $argList;
    }elsif($arg =~ /^(--use-screen-audio)$/){
      $useScreenAudio = 1;
    }elsif($arg =~ /^(--longest-audio)$/){
      $longestAudio = 1;
    }elsif($arg =~ /^(-a|--audio-only|--stop-after-audio)$/){
      $audioOnly = 1;
    }elsif($arg =~ /^--outputFile=(.+)$/){
      $outputFile = $1;
    }elsif($arg =~ /^--camera-volume=(\d+|\d*\.\d+)$/){
      $cameraVolume = $1;
    }elsif($arg =~ /^--song-volume=(\d+|\d*\.\d+)$/){
      $songVolume = $1;
    }elsif($arg =~ /^--camera-audio-offset=(\d+|\d*\.\d+)$/){
      $cameraAVSyncOffset = $1;
    }elsif($arg =~ /^--camera-audio-point=(\d+|\d*\.\d+)$/){
      $cameraAudioPoint = $1;
    }elsif($arg =~ /^--screen-point=(\d+|\d*\.\d+)$/){
      $screenPoint = $1;
    }elsif($arg =~ /^--song-point=(\d+|\d*\.\d+)$/){
      $songPoint = $1;
    }else{
      die "$usage\nERROR: unknown arg \"$arg\"\n";
    }
  }
  die "ERROR: CAMERA_FILE arg is missing or not a file\n" if not isFile($cameraFile);
  die "ERROR: SCREEN_FILE arg is missing or not a file\n" if not isFile($screenFile);
  die "ERROR: OUTPUT_FILE arg is missing\n" if not defined $outputFile;

  my $ext = $1 if $cameraFile =~ /\.(\w+)$/;
  die "ERROR: missing file extension in $cameraFile\n" if not defined $ext;

  my @cameraFpsFilter;
  my @ffprobeCmd = ("ffprobe",
    "-v", "error",
    "-select_streams", "v:0",
    "-show_entries", "stream=avg_frame_rate",
    "-of", "default=nw=1:nk=1",
    $cameraFile,
  );
  my $cameraInfo = `@ffprobeCmd 2>&1`;
  if($cameraInfo =~ /^(\d+)\/(\d+)$/){
    my $fps = $2 == 0 ? 0 : $1/$2;
    if($fps > 0){
      push @cameraFpsFilter, sprintf "fps=fps=%.3f", $fps;
    }else{
      print STDERR "WARNING: could not parse camera fps\n" if $fps <= 0;
    }
  }

  my ($cameraAudioStartPos, $screenAudioStartPos, $songAudioStartPos);
  if($useScreenAudio){
    if($screenPoint > $cameraAudioPoint){
      $cameraAudioStartPos = 0;
      $screenAudioStartPos = $screenPoint - $cameraAudioPoint;
      $songAudioStartPos = 0;
    }else{
      $cameraAudioStartPos = $cameraAudioPoint - $screenPoint;
      $screenAudioStartPos = 0;
      $songAudioStartPos = 0;
    }
  }elsif(isFile($songFile)){
    $cameraAudioStartPos = 0;
    $screenAudioStartPos = 0;
    $songAudioStartPos = $songPoint - $cameraAudioPoint;
    #presumably always negative, camera starts before song
  }else{
    $cameraAudioStartPos = 0;
    $screenAudioStartPos = 0;
    $songAudioStartPos = 0;
  }

  #increase camera volume
  ffmpeg("tmp-camera-audio.wav",
    "-i", $cameraFile,
    "-ss", "$cameraAudioStartPos",
    "-filter:a", "volume=$cameraVolume",
  );

  my $audioOverlay = undef;
  if($useScreenAudio){
    $audioOverlay = "tmp-audio-overlay-screen.wav";
    #extract song audio from screen
    ffmpeg($audioOverlay,
      "-i", $screenFile,
      "-ss", "$screenAudioStartPos",
      "-filter:a", "volume=$songVolume",
    );
  }elsif(isFile($songFile)){
    #delay the song-audio to match the start of the camera audio
    # (camera always starts before the song)
    my $songSilencePrefixLen = 0 - $songAudioStartPos;
    $audioOverlay = "tmp-audio-overlay-song.wav";
    ffmpeg($audioOverlay,
      "-f", "lavfi",
      "-t", sprintf("%.2f", $songSilencePrefixLen),
      "-i", "anullsrc=channel_layout=stereo:sample_rate=44100",
      "-i", $songFile,
      "-filter_complex", join(",",
        "[0:a][1:a]concat=n=2:v=0:a=1",
        "volume=$songVolume",
      ),
    );
  }

  if(defined $audioOverlay){
    #overlay camera+song audio
    if($longestAudio){
      ffmpeg("tmp-audio-final.wav",
        "-i", $audioOverlay,
        "-i", "tmp-camera-audio.wav",
        "-filter_complex", "amix=inputs=2:duration=longest",
      );
    }else{
      ffmpeg("tmp-audio-final.wav",
        "-i", "tmp-camera-audio.wav",
        "-i", $audioOverlay,
        "-filter_complex", "amix=inputs=2:duration=shortest",
      );
    }
  }else{
    ffmpeg("tmp-audio-final.wav",
      "-i", "tmp-camera-audio.wav",
      "-c", "copy",
    );
  }

  if($audioOnly){
    print "audio only, skipping video\n";
    exit 0;
  }

  my $cameraVideoPoint = $cameraAudioPoint + $cameraAVSyncOffset;

  my ($screenVideoStartPos, $cameraVideoStartPos);
  if($screenPoint > $cameraVideoPoint){
    $screenVideoStartPos = $screenPoint - $cameraVideoPoint;
    $cameraVideoStartPos = 0;
  }else{
    $screenVideoStartPos = 0;
    $cameraVideoStartPos = $cameraVideoPoint - $screenPoint;
  }

  #trim screen-video to start of camera-video, trim+resize for stacking
  ffmpeg("tmp-screen-trim-crop-scale-fps.$ext",
    "-i", $screenFile,
    "-ss", sprintf("%.2f", $screenVideoStartPos),
    "-filter_complex", join(",",
      "crop=875:720:0:0",           #1280x720 => 875x720     (crop room for camera)
      "scale=1312:1080",            #875x720  => 1312x1080   (720p => 1080p)
      @cameraFpsFilter,             #adjust to match camera
    ),
    "-an",
  );

  #trim camera-video to start of screen-video, rotate+resize camera-video for stacking
  ffmpeg("tmp-camera-transpose-scale.$ext",
    "-i", $cameraFile,
    "-ss", sprintf("%.2f", $cameraVideoStartPos),
    "-metadata:s:v:0", "rotate=0",  #remove metadata fake rotation
    "-filter_complex", join(",",
      "transpose=3",                #fix metadata confusion bug
      "transpose=3",                #actually rotate (same as overall transpose=1)
      "scale=608:1080",             #1080x1920 => 608x1080
    ),
    "-an",
  );

  #stack camera-video (left) and screen-video (right) horizontally
  ffmpeg("tmp-video-final.$ext",
    "-i", "tmp-camera-transpose-scale.$ext",
    "-i", "tmp-screen-trim-crop-scale-fps.$ext",
    "-vsync", "2",
    "-filter_complex", "hstack=inputs=2:shortest=1",
    "-an",
  );

  my $itsOffset;
  if($cameraVideoStartPos > 0){
    #camera video trimmed already, so audio a/v sync offset fixed there instead of here
    $itsOffset = 0;
  }else{
    $itsOffset = $cameraAVSyncOffset;
  }

  #combine video and audio with the AV sync matching camera file, unless corrected earlier
  ffmpeg($outputFile,
    "-i", "tmp-video-final.$ext",
    "-itsoffset", sprintf("%.2f", $itsOffset),
    "-i", "tmp-audio-final.wav",
    "-c:v", "copy",
  );

  system "touch", $outputFile, "-r", $cameraFile;
}

sub isFile($){
  return 0 if not defined $_[0];
  return -f $_[0] ? 1 : 0;
}

sub ffmpeg($@){
  my ($output, @opts) = @_;
  my @cmd = ("ffmpeg");
  @cmd = (@cmd, @INITIAL_OPTS, @opts, @EXTRA_OPTS, $output);

  print "@cmd\n";
  if(-f $output){
    print "  #skipped @cmd\n";
  }else{
    system @cmd;
    my $exitCode = $?;
    print "  #ran @cmd\n";
    die "FAILED\n" if $exitCode != 0;
  }
}

&main(@ARGV);
